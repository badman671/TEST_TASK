{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nimport statsmodels.api as sm\nimport statsmodels.stats.api as sms\nimport statsmodels.stats.proportion as smp\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import pearsonr\nimport sqlite3\n\n# Подключение к базе данных\ndb_file_path = 'path_to_your_database/testcase.db'\nconn = sqlite3.connect(db_file_path)\n\n# Задание 1: Успешность прототипа\n\n# Классический подход\nsuccessful_prototypes_our = 0\ntotal_prototypes_our = 200\n\n# Вероятность успеха следующего прототипа\n# В классическом подходе вероятность рассчитывается как отношение успешных прототипов к общему числу прототипов\nprob_success_classic = successful_prototypes_our / total_prototypes_our if total_prototypes_our > 0 else 0\n\n# Баесовский подход\n# Параметры априорного распределения Beta(1, 1) - это равномерное распределение\nalpha_prior = 1\nbeta_prior = 1\n\n# Параметры апостериорного распределения Beta обновляются с учетом наблюдаемых данных\nalpha_posterior = alpha_prior + successful_prototypes_our\nbeta_posterior = beta_prior + total_prototypes_our - successful_prototypes_our\n\n# Апостериорное распределение\nposterior_distribution = stats.beta(alpha_posterior, beta_posterior)\n\n# Вероятность успеха 201-го прототипа - среднее апостериорного распределения\nprobability_success_201 = posterior_distribution.mean()\n\nprint(\"Задание 1: Успешность прототипа\")\nprint(f\"Классический подход: {prob_success_classic}\")\nprint(f\"Баесовский подход: {probability_success_201}\")\n\n# Задание 2: Сравнение групп платящих игроков\n\n# 1. Дизайн эксперимента:\n# Оптимальный дизайн эксперимента включает случайное разделение новых игроков на контрольную и экспериментальную группы.\n# Контрольная группа не получает обновление, экспериментальная группа получает.\n# Сбор данных о проценте платящих игроков в обеих группах.\n# Анализ разницы в процентах платящих игроков между группами с использованием статистических методов.\n\n# 2. Расчет длительности эксперимента\n# Параметры\ndaily_new_players = 100\ncontrol_conversion_rate = 0.10\nexpected_conversion_rate = 0.11\nalpha = 0.05  # уровень значимости\npower = 0.80  # мощность теста\n\n# Размер эффекта рассчитывается на основе разницы между ожидаемым и текущим уровнем конверсии\neffect_size = sms.proportion_effectsize(control_conversion_rate, expected_conversion_rate)\n\n# Расчет размера выборки для каждой группы\nsample_size = sms.NormalIndPower().solve_power(effect_size, power=power, alpha=alpha, ratio=1)\nsample_size = int(np.ceil(sample_size))\n\n# Количество дней для эксперимента рассчитывается исходя из ежедневного притока новых игроков\ndays_needed = sample_size / daily_new_players\nprint(\"\\nЗадание 2: Сравнение групп платящих игроков\")\nprint(f\"Размер выборки для каждой группы: {sample_size}\")\nprint(f\"Количество дней для эксперимента: {days_needed}\")\n\n# 3. Генерация датасета с 10% плательщиков (контроль)\nnp.random.seed(42)  # Устанавливаем seed для воспроизводимости результатов\n\n# Размеры групп\nn_control = sample_size\nn_experiment = sample_size\n\n# Генерация контрольной группы (10% платящих)\ncontrol_group = np.random.binomial(1, control_conversion_rate, n_control)\n\n# Генерация экспериментальных групп с разными процентами платящих\nexperiment_group_9 = np.random.binomial(1, 0.09, n_experiment)\nexperiment_group_10 = np.random.binomial(1, 0.10, n_experiment)\nexperiment_group_11 = np.random.binomial(1, 0.11, n_experiment)\nexperiment_group_12 = np.random.binomial(1, 0.12, n_experiment)\n\n# Создание DataFrame для удобства\ndata = pd.DataFrame({\n    'group': ['control'] * n_control + ['experiment_9'] * n_experiment + ['experiment_10'] * n_experiment + ['experiment_11'] * n_experiment + ['experiment_12'] * n_experiment,\n    'payment': np.concatenate([control_group, experiment_group_9, experiment_group_10, experiment_group_11, experiment_group_12])\n})\n\n# 4. Расчет доверительных интервалов для контрольной и экспериментальных групп\n\n# Функция для расчета доверительных интервалов\ndef calculate_confidence_interval(data, group_name, alpha=0.05):\n    group_data = data[data['group'] == group_name]['payment']\n    successes = group_data.sum()  # Количество успешных (платящих) игроков\n    nobs = len(group_data)  # Общее количество игроков в группе\n    ci_lower, ci_upper = smp.proportion_confint(successes, nobs, alpha=alpha, method='normal')\n    return (ci_lower, ci_upper)\n\n# Доверительные интервалы для контрольной группы\nci_control = calculate_confidence_interval(data, 'control')\n\n# Доверительные интервалы для экспериментальных групп\nci_experiment_9 = calculate_confidence_interval(data, 'experiment_9')\nci_experiment_10 = calculate_confidence_interval(data, 'experiment_10')\nci_experiment_11 = calculate_confidence_interval(data, 'experiment_11')\nci_experiment_12 = calculate_confidence_interval(data, 'experiment_12')\n\nprint(f\"Доверительный интервал для контрольной группы (10% плательщиков): {ci_control}\")\nprint(f\"Доверительный интервал для экспериментальной группы 9%: {ci_experiment_9}\")\nprint(f\"Доверительный интервал для экспериментальной группы 10%: {ci_experiment_10}\")\nprint(f\"Доверительный интервал для экспериментальной группы 11%: {ci_experiment_11}\")\nprint(f\"Доверительный интервал для экспериментальной группы 12%: {ci_experiment_12}\")\n\n# 5. Баесовский подход: расчет HDI для контрольной и экспериментальных групп\n\n# Функция для расчета HDI (Highest Density Interval - Интервал наибольшей плотности)\ndef calculate_hdi(trace, hdi_prob=0.95):\n    return np.percentile(trace, [(1 - hdi_prob) / 2 * 100, (1 + hdi_prob) / 2 * 100])\n\n# Функция для баесовского анализа\ndef bayesian_analysis(data, group_name, alpha_prior=1, beta_prior=1, hdi_prob=0.95):\n    group_data = data[data['group'] == group_name]['payment']\n    successes = group_data.sum()  # Количество успешных (платящих) игроков\n    nobs = len(group_data)  # Общее количество игроков в группе\n    \n    # Апостериорное распределение\n    alpha_posterior = alpha_prior + successes\n    beta_posterior = beta_prior + nobs - successes\n    posterior_distribution = stats.beta(alpha_posterior, beta_posterior)\n    \n    # Генерация выборок из апостериорного распределения\n    samples = posterior_distribution.rvs(10000)\n    \n    # Расчет HDI\n    hdi_interval = calculate_hdi(samples, hdi_prob=hdi_prob)\n    \n    return hdi_interval\n\n# Расчет HDI для каждой группы\nhdi_control = bayesian_analysis(data, 'control')\nhdi_experiment_9 = bayesian_analysis(data, 'experiment_9')\nhdi_experiment_10 = bayesian_analysis(data, 'experiment_10')\nhdi_experiment_11 = bayesian_analysis(data, 'experiment_11')\nhdi_experiment_12 = bayesian_analysis(data, 'experiment_12')\n\nprint(f\"HDI для контрольной группы (10% плательщиков): {hdi_control}\")\nprint(f\"HDI для экспериментальной группы 9%: {hdi_experiment_9}\")\nprint(f\"HDI для экспериментальной группы 10%: {hdi_experiment_10}\")\nprint(f\"HDI для экспериментальной группы 11%: {hdi_experiment_11}\")\nprint(f\"HDI для экспериментальной группы 12%: {hdi_experiment_12}\")\n\n# Задание 4: Эффективность рекламных кампаний\n\n# 1. Подтверждение или опровержение гипотезы\n\n# Загрузка данных из таблицы costs\nquery_costs = \"SELECT * FROM costs\"\ncosts_data = pd.read_sql_query(query_costs, conn)\n\n# Загрузка данных из таблицы revenue\nquery_revenue = \"SELECT * FROM revenue\"\nrevenue_data = pd.read_sql_query(query_revenue, conn)\n\n# Объединение таблиц costs и revenue по campaign_id и Install_Dates\nmerged_data = pd.merge(costs_data, revenue_data, on=['campaign_id', 'Install_Dates', 'Country'])\n\n# Расчет ROAS на 60-й день\nmerged_data['ROAS_60d'] = merged_data['60d_LTV'] / merged_data['spends']\n\n# Визуализация зависимости ROAS от затрат\nplt.figure(figsize=(10, 6))\nsns.scatterplot(data=merged_data, x='spends', y='ROAS_60d')\nplt.xlabel('Затраты (COST)')\nplt.ylabel('ROAS на 60-й день')\nplt.title('Зависимость ROAS на 60-й день от затрат')\nplt.show()\n\n# Корреляционный анализ\ncorrelation = merged_data[['spends', 'ROAS_60d']].corr()\nprint(\"Корреляционный анализ между затратами и ROAS на 60-й день:\")\nprint(correlation)\n\n# 2. Оптимизация бюджета\n# Расчет маркетинговой прибыли для каждой кампании\nmerged_data['marketing_profit'] = merged_data['60d_LTV'] - merged_data['spends']\n\n# Группировка данных по campaign_id и расчет среднего значения прибыли\nprofit_by_campaign = merged_data.groupby('campaign_id')['marketing_profit'].mean().reset_index()\n\n# Поиск максимальной прибыли и соответствующего бюджета\nmax_profit_campaign = profit_by_campaign.loc[profit_by_campaign['marketing_profit'].idxmax()]\nprint(f\"Кампания с максимальной средней маркетинговой прибылью: {max_profit_campaign}\")\n\n# 3. Рекомендации по бюджетам\n# Добавление среднего значения прибыли в исходные данные\nmerged_data = merged_data.merge(profit_by_campaign, on='campaign_id', suffixes=('', '_mean'))\n\n# Рекомендации по бюджетам\nmerged_data['recommendation'] = merged_data['marketing_profit_mean'].apply(\n    lambda x: 'Increase budget' if x > 0 else 'Decrease budget or stop'\n)\n\n# Вывод рекомендаций для первых нескольких кампаний\nrecommendations = merged_data[['campaign_id', 'marketing_profit_mean', 'recommendation']].drop_duplicates()\nprint(\"Рекомендации по бюджетам для первых нескольких кампаний:\")\nprint(recommendations.head())\n\n# Задание 5: Связь рекламного и органического трафика\n\n# Загрузка данных из таблицы source_comparison\nquery_source_comparison = \"SELECT * FROM source_comparison\"\nsource_comparison_data = pd.read_sql_query(query_source_comparison, conn)\n\n# Преобразование даты в формат datetime\nsource_comparison_data['Install_Dates'] = pd.to_datetime(source_comparison_data['Install_Dates'])\n\n# Группировка данных по дате и источнику\ndaily_installs = source_comparison_data.groupby(['Install_Dates', 'source_type'])['installs'].sum().unstack().fillna(0)\n\n# Визуализация ежедневных установок\nplt.figure(figsize=(14, 7))\ndaily_installs.plot()\nplt.xlabel('Дата')\nplt.ylabel('Количество установок')\nplt.title('Ежедневные установки: рекламный и органический источники')\nplt.show()\n\n# Модель линейной регрессии для проверки зависимости\nX = daily_installs['Paid']\ny = daily_installs['Organic']\nX = sm.add_constant(X)\n\nmodel = sm.OLS(y, X).fit()\nsummary = model.summary()\nprint(\"Результаты регрессионного анализа:\")\nprint(summary)\n\n# Тест на независимость Пирсона\ncorrelation, p_value = pearsonr(daily_installs['Paid'], daily_installs['Organic'])\nprint(f\"Коэффициент корреляции Пирсона: {correlation}\")\nprint(f\"p-value: {p_value}\")\n\n# Закрытие соединения с базой данных\nconn.close()\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
